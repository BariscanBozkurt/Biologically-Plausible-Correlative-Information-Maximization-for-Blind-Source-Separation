{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9aa7574",
   "metadata": {},
   "source": [
    "# THIS NOTEBOOK USES OUR ORIGINAL OLD IMPLEMENTATION.\n",
    "# MAKE IT COMPATIBLE WITH THE NEW VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018a642",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"./src\")\n",
    "# sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from WSMBSS import *\n",
    "from numba import njit\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(100)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "notebook_name = \"Simplex\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0071175",
   "metadata": {},
   "source": [
    "# Source Generation and Mixing Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "NumberofSources = 5\n",
    "NumberofMixtures = 10\n",
    "N = 500000\n",
    "# https://stackoverflow.com/questions/65154622/sample-uniformly-at-random-from-a-simplex-in-python\n",
    "S = np.random.exponential(scale=1.0, size=(NumberofSources, int(N)))\n",
    "S = S / np.sum(S, axis=0)\n",
    "\n",
    "SNR = 30\n",
    "A = np.random.randn(NumberofMixtures, NumberofSources)\n",
    "X = np.dot(A, S)\n",
    "np.random.seed(100)\n",
    "X, NoisePart = addWGN(X, SNR, return_noise=True)\n",
    "\n",
    "SNRinp = 10 * np.log10(\n",
    "    np.sum(np.mean((X - NoisePart) ** 2, axis=1))\n",
    "    / np.sum(np.mean(NoisePart**2, axis=1))\n",
    ")\n",
    "print(\"The following is the mixture matrix A\")\n",
    "display_matrix(A)\n",
    "print(\"Input SNR is : {}\".format(SNRinp))\n",
    "\n",
    "plt.scatter(S[0, :], S[2, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42a1cf",
   "metadata": {},
   "source": [
    "# Visualize Generated Sources and Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0df841",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_1D_signals(\n",
    "    S.T[0:100], title=\"Original Signals\", figsize=(15.2, 9), colorcode=None\n",
    ")\n",
    "subplot_1D_signals(\n",
    "    X.T[0:100], title=\"Mixture Signals\", figsize=(15, 18), colorcode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e665e",
   "metadata": {},
   "source": [
    "# Algorithm Hyperparameter Selection and Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MUS = 0.35\n",
    "OUTPUT_COMP_TOL = 1e-5\n",
    "MAX_OUT_ITERATIONS = 3000\n",
    "LayerGains = [1, 1]\n",
    "LayerMinimumGains = [1, 1]\n",
    "LayerMaximumGains = [1e6, 1.001]\n",
    "WScalings = [0.0033, 0.0033]\n",
    "GamScalings = [0.01, 0.1]\n",
    "zeta = 1e-4\n",
    "beta = 0.5\n",
    "muD = [20, 1e-2]\n",
    "\n",
    "# OPTIONS FOR synaptic_lr_rule: \"constant\", \"divide_by_log_index\", \"divide_by_index\"\n",
    "synaptic_lr_rule = \"divide_by_log_index\"\n",
    "# OPTIONS FOR neural_loop_lr_rule: \"constant\", \"divide_by_loop_index\", \"divide_by_slow_loop_index\"\n",
    "neural_loop_lr_rule = \"divide_by_slow_loop_index\"\n",
    "s_dim = S.shape[0]\n",
    "x_dim = X.shape[0]\n",
    "h_dim = s_dim\n",
    "samples = S.shape[1]\n",
    "W_HX = np.eye(h_dim, x_dim)\n",
    "W_YH = np.eye(s_dim, h_dim)\n",
    "\n",
    "# MUS = 0.25\n",
    "# OUTPUT_COMP_TOL = 1e-5\n",
    "# MAX_OUT_ITERATIONS= 3000\n",
    "# LayerGains = [1,1]\n",
    "# LayerMinimumGains = [.51,.51]\n",
    "# LayerMaximumGains = [1e6,1.001]\n",
    "# WScalings = [0.0033,0.0033]\n",
    "# GamScalings = [0.01,0.01]\n",
    "# zeta = 1e-4\n",
    "# beta = 0.5\n",
    "# muD = [5, 1]\n",
    "\n",
    "# s_dim = S.shape[0]\n",
    "# x_dim = X.shape[0]\n",
    "# h_dim = s_dim\n",
    "# samples = S.shape[1]\n",
    "# W_HX = np.eye(h_dim, x_dim)\n",
    "# W_YH = np.eye(s_dim, h_dim)\n",
    "\n",
    "MUS = 0.25\n",
    "OUTPUT_COMP_TOL = 1e-5\n",
    "MAX_OUT_ITERATIONS = 3000\n",
    "LayerGains = [1, 1]\n",
    "LayerMinimumGains = [1, 1]\n",
    "LayerMaximumGains = [1e6, 1.001]\n",
    "WScalings = [0.0033, 0.0033]\n",
    "GamScalings = [0.01, 0.01]\n",
    "zeta = 1e-4\n",
    "beta = 0.5\n",
    "muD = [20, 1e-2]\n",
    "\n",
    "s_dim = S.shape[0]\n",
    "x_dim = X.shape[0]\n",
    "h_dim = s_dim\n",
    "samples = S.shape[1]\n",
    "W_HX = np.eye(h_dim, x_dim)\n",
    "W_YH = np.eye(s_dim, h_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa7a36",
   "metadata": {},
   "source": [
    "# Run WSM Algorithm on Mixture Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_iteration_point = 10000\n",
    "\n",
    "model = OnlineWSMBSS(\n",
    "    s_dim=s_dim,\n",
    "    x_dim=x_dim,\n",
    "    h_dim=h_dim,\n",
    "    gamma_start=MUS,\n",
    "    beta=beta,\n",
    "    zeta=zeta,\n",
    "    muD=muD,\n",
    "    WScalings=WScalings,\n",
    "    W_HX=W_HX,\n",
    "    W_YH=W_YH,\n",
    "    DScalings=LayerGains,\n",
    "    LayerMinimumGains=LayerMinimumGains,\n",
    "    LayerMaximumGains=LayerMaximumGains,\n",
    "    neural_OUTPUT_COMP_TOL=OUTPUT_COMP_TOL,\n",
    "    set_ground_truth=True,\n",
    "    S=S,\n",
    "    A=A,\n",
    ")\n",
    "\n",
    "model.fit_batch_simplex(\n",
    "    X,\n",
    "    n_epochs=1,\n",
    "    neural_lr_start=0.9,\n",
    "    shuffle=False,\n",
    "    debug_iteration_point=debug_iteration_point,\n",
    "    plot_in_jupyter=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d9cde",
   "metadata": {},
   "source": [
    "# Visualize SNR Convergence of Each Source Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"xtick.labelsize\"] = 18\n",
    "mpl.rcParams[\"ytick.labelsize\"] = 18\n",
    "plot_convergence_plot(\n",
    "    model.SNR_list,\n",
    "    xlabel=\"Number of Iterations / {}\".format(debug_iteration_point),\n",
    "    ylabel=\"SINR (dB)\",\n",
    "    title=\"SINR Convergence Plot\",\n",
    "    colorcode=None,\n",
    "    linewidth=1.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e3c6e",
   "metadata": {},
   "source": [
    "# Calculate Resulting Component SNRs and Overall SINR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f814ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Szeromean = S - S.mean(axis=1).reshape(-1, 1)\n",
    "Wf = model.compute_overall_mapping(return_mapping=True)\n",
    "Y = Wf @ X\n",
    "Yzeromean = Y - Y.mean(axis=1).reshape(-1, 1)\n",
    "Y_ = signed_and_permutation_corrected_sources(Szeromean.T, Yzeromean.T)\n",
    "coef_ = (Y_ * Szeromean.T).sum(axis=0) / (Y_ * Y_).sum(axis=0)\n",
    "Y_ = coef_ * Y_\n",
    "print(\"Component SNR Values : {}\\n\".format(snr(Szeromean.T, Y_)))\n",
    "\n",
    "SINRwsm = 10 * np.log10(CalculateSINR(Y_.T, Szeromean, False)[0])\n",
    "\n",
    "print(\"Overall SINR : {}\".format(SINRwsm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1072c7",
   "metadata": {},
   "source": [
    "# Vizualize Extracted Signals Compared to Original Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b221b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2500\n",
    "subplot_1D_signals(\n",
    "    Y_.T[k : k + 100],\n",
    "    title=\"Extracted Signals (Sign and Permutation Corrected)\",\n",
    "    figsize=(15.2, 9),\n",
    "    colorcode=None,\n",
    ")\n",
    "subplot_1D_signals(\n",
    "    S.T[k : k + 100], title=\"Original Signals\", figsize=(15.2, 9), colorcode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1361aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8536b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape, Y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mir_eval.separation.bss_eval_sources(S, Y_, compute_permutation=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
